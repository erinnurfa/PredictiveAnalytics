# -*- coding: utf-8 -*-
"""Erin_Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cJtnj-PQRetbt9Gx-bliJzW18gJpfGmo

Nama : Erin Nur Fatimah

ID : M515Y1092

Alamat : Sindet RT 003, Wukirsari, Imogiri, Bantul, Yogyakarta

# Data Loading
"""

from google.colab import drive

drive.mount('/content/drive')

"""### Mengimport Library yang Dibutuhkan"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""### Melihat isi dataset
Melihat isi dataset menggunakan Pandas beserta melihat isi df.info() 
"""

ds = pd.read_csv('/content/drive/MyDrive/milknew.csv')
ds

"""Output kode di atas memberikan informasi sebagai berikut :

* Ada 1059 baris baris (records atau jumlah pengamatan) dalam dataset.
* Terdapat 8 kolom yaitu: pH, Temperature, Taste, Odor, Fat, Turbidity, Colour, Grade

# Deskripsi Variabel

### Membuat kolom type pada dataset
"""

ds.info()

"""bisa dilihat ada 8 kolom yaitu 

* pH
* Temperature 
* Taste 
* Odor
* Fat 
* Turbidity 
* Colour
* Grade

### Mengecek deskripsi statistik data
"""

ds.describe()

"""Fungsi describe() memberikan informasi statistik pada masing-masing kolom. Pada tabel di atas memperlihatkan bahwa fitur pH, Temprature, dan Colour. dikelompokkan ke dalam fitur numerical. Sedangkan untuk fitur lainnya dikelompokkan ke dalam fitur kategori karena hanya terdiri dari 0 dan 1.

# Menangani Missing Value

### Menghitung jumlah data kosong pada setiap kolom
"""

ds.isna().sum()

"""dapat kita lihat bahwa tidak terdapat data kosong

### Memuat ukuran shape pada dataframe
"""

ds.shape

"""### Mengklasifikasikan fitur categorical, numerical, dan target"""

# Mengklasifikasikan fitur categorical
cat_features = ['Taste','Odor','Fat','Turbidity']

# Mengklasifikasikan fitur numerical
num_features = ['pH','Temprature','Colour']

# Mengklasifikasikan fitur yang menjadi target
target_features = 'Grade'

"""# Menangani Outlier"""

sns.set(font_scale=2)
fig, axes = plt.subplots(
    nrows=1,
    ncols=len(num_features),
    figsize=(30,15)
)
for indeks in range(len(num_features)):
    # Menggunakan boxplot untuk visualisasi nilai data pada fitur numerical
    ax = sns.boxplot(
        y=ds[num_features[indeks]],
        ax=axes[indeks]
    )
    axes[indeks].set_xlabel(num_features[indeks])
    axes[indeks].set_ylabel('Nilai')

fig.suptitle('Distribusi Outliers')

Q1 = ds.quantile(0.25)
Q3 = ds.quantile(0.75)
IQR = Q3-Q1
ds = ds[~( (ds<(Q1-1.5*IQR)) | (ds>(Q3+1.5*IQR)) ).any(axis=1)]

# Mengecek ukuran dataset setelah kita drop outliers
ds.shape

"""# Univariate Analysis"""

# Membagi fitur dataset menjadi fitur categorical, numerical, dan target
cat_features = ['Taste','Odor','Fat','Turbidity']
num_features = ['pH','Temprature','Colour']
target_features = 'Grade'

"""# Multivariate Analysis

### Encoding Fitur Target
"""

ds['Grade'].replace({
    'low':0,
    'medium':1,
    'high':2
}, inplace=True)

"""### Membuat plot untuk menampilkan grafik beberapa fitur"""

plt.figure(figsize=(20,15))

plt.subplot(3,3,1)
sns.countplot(x='pH', hue='Grade', data=ds)
plt.subplot(3,3,2)
sns.countplot(x='Temprature', hue='Grade', data=ds)
plt.subplot(3,3,3)
sns.countplot(x='Taste', hue='Grade', data=ds)

plt.subplot(3,3,4)
sns.countplot(x='Odor', hue='Grade', data=ds)
plt.subplot(3,3,5)
sns.countplot(x='Turbidity', hue='Grade', data=ds)
plt.subplot(3,3,6)
sns.countplot(x='Colour', hue='Grade', data=ds)

plt.tight_layout()
plt.show()

"""Bisa kita lihat pada beberapa variable plot diatas bahwa kualitas medium atau kelas menengah cukup tinggi dibandingkan dengan yang kualitas low ataupun yang hight.

### Melihat histogram masing-masing fitur
"""

ds.hist(bins=50, figsize=(20,15))
plt.show()

"""### Mengamati hubungan  antar fitur numerik dengan fungsi pairplot()"""

# Mengamati hubungan  antar fitur numerik dengan fungsi pairplot()
sns.pairplot(ds, diag_kind='kde')

"""### Melakukan cek pada Multivariate EDA dengan heatmap"""

plt.figure(figsize=(10, 8))
correlation_matrix = ds.corr().round(2)
 
# Untuk menge-print nilai di dalam kotak menggunakan parameter anot=True
mask = np.zeros_like(correlation_matrix)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""# Data Preparation

## Melakukan pembagian dataset dengan train_test_split
"""

from sklearn.model_selection import train_test_split

P = ds.iloc[:, :ds.columns.get_loc(target_features)]
Q = ds[target_features]
# Menggunakan proporsi pembagian sebesar 80:20
P_train, P_val, Q_train, Q_val = train_test_split(P, Q, test_size=0.2)

"""## Melakukan Standard Scaler"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
P_train[num_features] = scaler.fit_transform(P_train[num_features])

"""# Modeling

## 1. Model Development dengan Gradient Boosting
"""

from sklearn.ensemble import GradientBoostingClassifier

mod1 = GradientBoostingClassifier(random_state=123)
prm1 = {
    'classifier__n_estimators':[10,50,100,250],
    'classifier__max_depth':[5,10,20],
    'classifier':[mod1]
}

"""## 2. Model Development dengan Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

mod2 = DecisionTreeClassifier(random_state=123)
prm2 = {
    'classifier__max_depth':[5,10,25],
    'classifier__min_samples_split':[2,5,10],
    'classifier':[mod2]
}

"""## 3. Model Development dengan K-Nearest Neighbor"""

from sklearn.neighbors import KNeighborsClassifier

mod3 = KNeighborsClassifier()
prm3 = {
    'classifier__n_neighbors':[2,5,10,25,50,100],
    'classifier':[mod3]
}

"""## 4. Model Development dengan Random Forest"""

from sklearn.ensemble import RandomForestClassifier

mod4 = RandomForestClassifier(random_state=123)
prm4 = {
    'classifier__n_estimators':[10,50,100,250],
    'classifier__max_depth':[5,10,20],
    'classifier':[mod4]
}

"""## Membuat pipeline dan melakukan training pada model dan hyperparameter tuning"""

from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV

pipeline = Pipeline([('classifier', mod1)])
params = [prm1, prm2, prm3, prm4]
gs = GridSearchCV(pipeline, params, cv=3, n_jobs=-1, scoring='accuracy').fit(P_train, Q_train)

gs_results = pd.DataFrame(gs.cv_results_)[[
    'param_classifier',
    'params',
    'mean_test_score',
    'rank_test_score'
]].sort_values(by='rank_test_score')

gs_results.head(5)

"""# Evaluasi Model

## Skor akurasi pada data validasi dari model terbaik
"""

from sklearn.metrics import *

print(gs.best_params_)
print(gs.best_score_)
P_val[num_features] = scaler.transform(P_val[num_features])
print("Validation Score:",gs.score(P_val, Q_val))

def vis_eval(Q_val, val_pred):
    """
    Visualisasi performa model dengan metrik evaluasi
    - y_val ialah kumpulan nilai aktual dari fitur target pada data validasi (pd.DataFrame)
    - val_pred ialah kumpulan nilai prediksi dari fitur target pada data validasi (pd.DataFrame)
    """

    print('Classification Report')
    print(classification_report(Q_val, val_pred))
    print('Confusion Matrix')
    cm=confusion_matrix(Q_val, val_pred)
    cm=pd.DataFrame(cm)
    plt.figure(figsize=(10,10))
    sns.heatmap(cm,
            cmap= "coolwarm",
            annot=True,
            fmt='',
            xticklabels=['Low', 'Medium', 'Hight'],
            yticklabels=['Low', 'Medium', 'Hight'])
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

algorithm = gs.best_params_['classifier']
algorithm.fit(P_train, Q_train)
val_pred = algorithm.predict(P_val)

vis_eval(Q_val, val_pred)